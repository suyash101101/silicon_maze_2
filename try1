import requests
from bs4 import BeautifulSoup
import csv

companies = ['VOLTAS', 'BLUE STAR', 'CROMPTON', 'ORIENT ELECTRIC', 'HAVELLS', 'SYMPHONY', 'WHIRLPOOL']

def generate_url(company):
    return f"https://www.screener.in/company/{company}/consolidated/"

def get_and_parse(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup

def extract_data(soup):
    data = {}
    stats_section = soup.find_all('div', {'class': 'flex flw-wrp it'})

    if stats_section and len(stats_section) > 4:
        data['Market Cap'] = stats_section[0].find('span').text.strip()
        data['Stock P/E'] = stats_section[1].find('span').text.strip()
        data['ROCE'] = stats_section[2].find('span').text.strip()
        data['Current Price'] = stats_section[3].find('span').text.strip()
        data['ROE'] = stats_section[4].find('span').text.strip()
    return data

def write_to_csv(filename, data):
    with open(filename, 'w', newline='') as file:
        fieldnames = ['Company', 'Market Cap', 'Stock P/E', 'ROCE', 'Current Price', 'ROE']
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        for row in data:
            writer.writerow(row)

def scrape_pokemon_stats():
    all_data = []

    for company in companies:
        url = generate_url(company)
        soup = get_and_parse(url)
        data = extract_data(soup)
        data['Company'] = company
        all_data.append(data)

    write_to_csv('/Users/suyashnahar/Desktop/Basic_Pokemon_Stats.csv', all_data)

scrape_pokemon_stats()
